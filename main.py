# main.py
import os
import time
import Core
import logging
from langchain.chains import RetrievalQA
from Core.models import DocumentQASystem
from Core.document_loader import load_document
from Core.auto_test import perform_auto_test, visualize_results
from Utils.utils import print_help, export_to_excel

def process_command(command: str, qa_system: DocumentQASystem) -> bool:
    """å¤„ç†ç³»ç»Ÿå‘½ä»¤"""
    command = command.strip().lower()

    if command.startswith("/switch"):
        model_name = command.split()[-1] if len(command.split()) > 1 else ""
        if model_name in qa_system.llm_registry:
            qa_system.current_model = model_name
            qa_system._release_model_resources()
            qa_system.conversation_chain = None
            print(f"å·²åˆ‡æ¢åˆ° {model_name.upper()} æ¨¡å‹")
            return True
        else:
            print(f"âŒ æ— æ•ˆæ¨¡å‹ï¼Œå¯ç”¨é€‰é¡¹ï¼š{list(qa_system.llm_registry.keys())}")
            return False

    # main.py ä¸­çš„ process_command å‡½æ•°éƒ¨åˆ†
    elif command.startswith("/compare"):
        query_part = command[8:].strip()
        if not query_part:
            print("è¯·è¾“å…¥å¤šè¡ŒæŸ¥è¯¢ï¼ˆè¾“å…¥ç©ºè¡Œç»“æŸï¼‰ï¼š")
            lines = []
            while True:
                line = input().rstrip()
                if line == "":
                    break
                lines.append(line)
            query = "\n".join(lines)
        else:
            query = query_part

        if not query:
            print("è¯·æä¾›æŸ¥è¯¢å†…å®¹ï¼Œæ ¼å¼ï¼š/compare [æŸ¥è¯¢å†…å®¹]")
            return False

        print(f"\næ­£åœ¨æ¯”è¾ƒå„æ¨¡å‹çš„å“åº”...")
        results = {}
        for name, model in qa_system.llm_registry.items():
            try:
                start_time = time.time()
                if qa_system.qa_chain:  # æ£€æŸ¥æ˜¯å¦æœ‰æ–‡æ¡£ä¸Šä¼ 
                    # ä½¿ç”¨ qa_chain ç”ŸæˆåŸºäºæ–‡æ¡£çš„å›ç­”
                    qa_system.qa_chain = RetrievalQA.from_chain_type(
                        llm=model,
                        chain_type="stuff",
                        retriever=qa_system.vector_db.as_retriever(search_kwargs={"k": 3}),
                        return_source_documents=True
                    )
                    result = qa_system.qa_chain({"query": query})
                    response = f"{result['result']}\nğŸ“š æ¥æºï¼š{result['source_documents'][0].metadata['source']}"
                else:
                    # æ²¡æœ‰æ–‡æ¡£ä¸Šä¼ ï¼Œç›´æ¥è°ƒç”¨æ¨¡å‹
                    response = model.invoke(query)
                end_time = time.time()
                latency = end_time - start_time
                results[name] = {
                    "response": response,
                    "latency": f"{latency:.2f}s"
                }
                # é‡Šæ”¾èµ„æº
                del response
                qa_system._release_model_resources()
            except Exception as e:
                print(f"{name.upper()} è°ƒç”¨å‡ºé”™ï¼š{str(e)}")

        print("\næ¯”è¾ƒç»“æœï¼š")
        for model_name, data in results.items():
            print(f"{model_name.upper()}:")
            print(f"å»¶è¿Ÿï¼š{data['latency']}")
            print(f"å“åº”é¢„è§ˆï¼š{data['response'][:200]}...\n")

        export_file = export_to_excel(results, query)
        if export_file:
            print(f"\nå·²å¯¼å‡ºç»“æœè‡³ï¼š{os.path.abspath(export_file)}")
        else:
            print("âŒ \nå¯¼å‡ºç»“æœå¤±è´¥")
        return True

    # /autotest - è‡ªåŠ¨æµ‹è¯•å‘½ä»¤
    elif command.startswith("/autotest"):
        # è¯¢é—®æµ‹è¯•æ•°é‡
        logic_count = int(input("è¯·è¾“å…¥æµ‹è¯•çš„é€»è¾‘é¢˜æ•°é‡ï¼š"))
        read_count = int(input("è¯·è¾“å…¥æµ‹è¯•çš„é˜…è¯»ç†è§£é¢˜æ•°é‡ï¼š"))
        math_count = int(input("è¯·è¾“å…¥æµ‹è¯•çš„æ•°å­¦é¢˜æ•°é‡ï¼š"))

        # è°ƒç”¨ç›¸å…³å‡½æ•°åŠ è½½é—®é¢˜å¹¶è¿›è¡Œæµ‹è¯•
        print(f"å¼€å§‹è‡ªåŠ¨æµ‹è¯• {logic_count} é“é€»è¾‘é¢˜ï¼Œ{read_count} é“é˜…è¯»ç†è§£é¢˜ï¼Œ{math_count} é“æ•°å­¦é¢˜...")
        results, standard_answers = perform_auto_test(qa_system, logic_count, read_count, math_count)

        # å¯¼å‡ºå¹¶å¯è§†åŒ–ç»“æœ
        export_file = Core.auto_test.export_to_excel(results, "Sample Query", standard_answers)
        if export_file:
            print(f"\næµ‹è¯•ç»“æœå·²å¯¼å‡ºè‡³ï¼š{os.path.abspath(export_file)}")
            visualize_results(export_file)  # ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨
        else:
            print("âŒ å¯¼å‡ºç»“æœå¤±è´¥")

        return True

    elif command == "/help":
        print_help()
        return True

    elif command == "/upload":
        file_path = input("ğŸ“‚ è¯·è¾“å…¥æ–‡ä»¶è·¯å¾„ï¼š").strip()
        if not os.path.exists(file_path):
            print("âŒ æ–‡ä»¶ä¸å­˜åœ¨")
            return False
        if load_document(qa_system, file_path):
            print("ğŸ“„  æ–‡æ¡£åŠ è½½æˆåŠŸ")
            return True
        print("âŒ æ–‡æ¡£åŠ è½½å¤±è´¥")
        return False

    else:
        print("âŒ æœªçŸ¥å‘½ä»¤ï¼Œè¾“å…¥/helpæŸ¥çœ‹å¸®åŠ©")
        return False

def process_query(query: str, qa_system: DocumentQASystem, current_model: str) -> None:
    """å¤„ç†ç”¨æˆ·æŸ¥è¯¢"""
    try:
        if qa_system.qa_chain:
            result = qa_system.qa_chain({"query": query})
            response = f"{result['result']}\næ¥æºï¼š{result['source_documents'][0].metadata['source']}"
        else:
            if not qa_system.conversation_chain:
                from langchain.chains import ConversationChain
                qa_system.conversation_chain = ConversationChain(
                    llm=qa_system.llm_registry[qa_system.current_model],
                    memory=qa_system.memory
                )
            response = qa_system.conversation_chain.predict(input=query)

        print(f"\n{current_model.upper()}:", response)

    except Exception as e:
        error_msg = f"âŒ å¤„ç†é”™è¯¯ï¼š{str(e)}"
        logging.error(error_msg)
        print(error_msg)

def main():
    qa_system = DocumentQASystem()
    print_help()
    current_model = qa_system.current_model

    while True:
        try:
            # åˆå§‹åŒ–è¾“å…¥æ”¶é›†
            user_input = []
            print("\nYou: (è¾“å…¥å†…å®¹ï¼Œè¿æŒ‰ä¸¤æ¬¡å›è½¦æäº¤)")

            # å¤šè¡Œè¾“å…¥å¾ªç¯
            while True:
                line = input().strip()

                # é€€å‡ºæŒ‡ä»¤å¤„ç†
                if line.lower() in ["exit", "quit"]:
                    print("ğŸ‘‹  å†è§ï¼")
                    return

                # å‘½ä»¤ç«‹å³æ‰§è¡Œ
                if line.startswith("/"):
                    process_command(line, qa_system)
                    current_model = qa_system.current_model
                    break

                # ç©ºè¡Œè¡¨ç¤ºæäº¤è¾“å…¥
                if not line:
                    if user_input:
                        full_query = "\n".join(user_input)
                        print("ğŸ¤– Modelæ€è€ƒä¸­......")
                        process_query(full_query, qa_system, current_model)
                    user_input = []
                    break

                user_input.append(line)

        except KeyboardInterrupt:
            print("\nè¾“å…¥ä¸­æ–­ï¼Œè¾“å…¥ exit é€€å‡ºç¨‹åº")
        except Exception as e:
            logging.error(f"ç³»ç»Ÿé”™è¯¯ï¼š{str(e)}")
            print("âŒ å‘ç”Ÿæ„å¤–é”™è¯¯ï¼Œè¯·é‡æ–°å°è¯•")

if __name__ == "__main__":
    main()